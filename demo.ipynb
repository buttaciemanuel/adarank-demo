{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaRank implementation\n",
    "\n",
    "In this notebook we show a simple and effective implementation of AdaRank algorithm from paper [AdaRank: a boosting algorithm for information retrieval](https://dl.acm.org/doi/abs/10.1145/1277741.1277809?casa_token=ku7AGgHMiTsAAAAA:sm_rUCTguz9F5k2yANn2iLGLVwBFpMkQOB_zN9csd7zCH5mDSYBFOToYoQmP5ChVbOUidtZWFFgZxw) for listwise ranking of documents with respect to queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialization\n",
    "\n",
    "In this first part we setup the libraries installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas numpy sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we convert the raw csv dataset files into the expected format for the AdaRank algorithm. We choose to create a file of index pairs for (query, document) in order to avoid the redundancy given by queries and documents text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>document</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2</td>\n",
       "      <td>196</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2</td>\n",
       "      <td>199</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query  document  rank\n",
       "0        0         0    66\n",
       "1        0         1    16\n",
       "2        0         2    69\n",
       "3        0         3    59\n",
       "4        0         4    14\n",
       "..     ...       ...   ...\n",
       "196      2       196    31\n",
       "197      2       197    72\n",
       "198      2       198    76\n",
       "199      2       199    34\n",
       "200      2       200    88\n",
       "\n",
       "[201 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of document datasets for each query\n",
    "documents = []\n",
    "# list of queries\n",
    "queries = []\n",
    "# list of datasets of pair (query, document) with a random relevance score in [0, 100)\n",
    "pairs = []\n",
    "# progessive indices used to keep count\n",
    "dindex, qindex = 0, 0\n",
    "# each raw dataset is used to embody its data in a new format\n",
    "for file in os.listdir('raw'):\n",
    "    frame = pd.read_csv(os.path.join('raw', file), sep = ';')\n",
    "    query = file.removesuffix('.csv')\n",
    "    # easy re-naming\n",
    "    frame.rename(columns = { 'long_common_name': 'text', 'loinc_num': 'loinc' }, inplace = True)\n",
    "    # insert query and related documents\n",
    "    queries.append(query)\n",
    "    documents.append(frame)\n",
    "    # we insert (query-index, document-index, random relevance score) for each document retrieved in the query\n",
    "    pairs.extend([ (qindex, dindex + d, random.randint(0, 100)) for d in range(len(frame)) ])\n",
    "    # progressive update of indices\n",
    "    dindex += len(frame)\n",
    "    qindex += 1\n",
    "# concatenation among all queries of the documents\n",
    "documents = pd.concat(documents, axis = 0, ignore_index = True)\n",
    "loinc = documents['loinc']\n",
    "documents.drop(columns = 'loinc', inplace = True)\n",
    "documents['loinc'] = loinc\n",
    "documents.to_csv('data/documents.csv', sep = ',', index_label = 'document')\n",
    "# concatenation of all queries\n",
    "queries = pd.DataFrame({ 'text': queries })\n",
    "queries.to_csv('data/queries.csv', sep = ',', index_label = 'query')\n",
    "# concatenation of all pairs with relevance scores in a new file\n",
    "pairs = pd.DataFrame(pairs, columns=[ 'query', 'document', 'rank' ])\n",
    "pairs.to_csv('data/pairs.csv', sep = ',')\n",
    "\n",
    "pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature extraction\n",
    "\n",
    "For our feature extraction mecahnism we combine each document and query by extracting three features.\n",
    "\n",
    "| Feature                   | Computation                                                                             |\n",
    "|---------------------------|-----------------------------------------------------------------------------------------|\n",
    "| log-frecency sum          | $\\sum_{\\forall w_j \\, \\in \\, d \\, \\cup \\, q} \\log(1 + \\text{count}(w_j, d)) $           |\n",
    "| log-frecency sum          | $\\sum_{\\forall w_j \\, \\in \\, d \\, \\cup \\, q} \\log(\\text{tf-idf}(w_j, d)) $              |\n",
    "| log-inverse-frequency sum | $\\sum_{\\forall w_j \\, \\in \\, d \\, \\cup \\, q} \\log(1 + 1 / (1 + \\text{count}(w_j, d))) $ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>log-frecency</th>\n",
       "      <th>tf-idf</th>\n",
       "      <th>log-inverse-frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.158883</td>\n",
       "      <td>2.261813</td>\n",
       "      <td>77.292686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>1.844363</td>\n",
       "      <td>77.868050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.686473</td>\n",
       "      <td>78.155732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.697418</td>\n",
       "      <td>78.155732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4.158883</td>\n",
       "      <td>2.335105</td>\n",
       "      <td>77.292686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.569326</td>\n",
       "      <td>79.542027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>79.542027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.390079</td>\n",
       "      <td>79.829709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2</td>\n",
       "      <td>4.852030</td>\n",
       "      <td>2.465639</td>\n",
       "      <td>78.391298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.701545</td>\n",
       "      <td>79.542027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query  log-frecency    tf-idf  log-inverse-frequency\n",
       "0        0      4.158883  2.261813              77.292686\n",
       "1        0      2.772589  1.844363              77.868050\n",
       "2        0      2.079442  1.686473              78.155732\n",
       "3        0      2.079442  1.697418              78.155732\n",
       "4        0      4.158883  2.335105              77.292686\n",
       "..     ...           ...       ...                    ...\n",
       "196      2      2.079442  1.569326              79.542027\n",
       "197      2      2.079442  1.732051              79.542027\n",
       "198      2      1.386294  1.390079              79.829709\n",
       "199      2      4.852030  2.465639              78.391298\n",
       "200      2      2.079442  1.701545              79.542027\n",
       "\n",
       "[201 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = None\n",
    "labels = None\n",
    "queries_words = queries['text'].astype('string').str.lower().str.split()\n",
    "# we build vocabularies and features\n",
    "for query, indices in pairs.groupby('query').groups.items():\n",
    "    # we select documents text for current query\n",
    "    documents_selected = documents.loc[pairs.loc[indices, 'document'], 'text']\n",
    "    # and all the tokenized words\n",
    "    documents_words = TfidfVectorizer(stop_words = 'english', binary = False).fit(documents_selected).get_feature_names_out()\n",
    "    # to such vocabulary we add tokens from the query's text\n",
    "    vocabulary = set(documents_words.tolist()).union(queries_words.iloc[query])\n",
    "    # we build the design matrix for current query with all fancy features\n",
    "    matrix = pd.DataFrame({\n",
    "        'query': query,\n",
    "        'log-frecency': pd.DataFrame(\n",
    "            CountVectorizer(stop_words = 'english', binary = False, vocabulary = vocabulary).fit_transform(documents_selected).todense()\n",
    "        ).apply(lambda x: np.log(1 + x)).sum(axis = 1),\n",
    "        'tf-idf': pd.DataFrame(\n",
    "            TfidfVectorizer(stop_words = 'english', binary = False, use_idf = True, vocabulary = vocabulary).fit_transform(documents_selected).todense(), \n",
    "        ).sum(axis = 1),\n",
    "        'log-inverse-frequency': pd.DataFrame(\n",
    "            CountVectorizer(stop_words = 'english', binary = False, vocabulary = vocabulary).fit_transform(documents_selected).todense()\n",
    "        ).apply(lambda x: np.log(1 + 1 / (1 + x))).sum(axis = 1),\n",
    "    })\n",
    "    # we concatenate each feature matrix\n",
    "    if features is None:\n",
    "        features = matrix\n",
    "    else:\n",
    "        features = pd.concat([ features, matrix ], axis = 0, ignore_index = True)\n",
    "    # we concatenate each label vector\n",
    "    if labels is None:\n",
    "        labels = pairs.loc[indices, 'rank']\n",
    "    else:\n",
    "        labels = pd.concat([ labels, pairs.loc[indices, 'rank'] ], axis = 0, ignore_index = True)\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. AdaRank implementation\n",
    "\n",
    "For our implementation we follow the explanation from the paper and we extend Scikit-Learn base class. Besides, we use NDCG score for evaluating the performance of weak rankers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaRank(BaseEstimator):\n",
    "\n",
    "    def __init__(self, n_rounds: int = 10, metric: str = 'ndcg') -> None:\n",
    "        super().__init__()\n",
    "        # number of training rounds\n",
    "        self.n_rounds = n_rounds\n",
    "        # performance metrics, by default NDCG\n",
    "        self.scorer_ = ndcg_score if metric else None\n",
    "        # alphas coefficients for weighting rankers' importances\n",
    "        self.alphas_ = np.empty(n_rounds, dtype = np.float32)\n",
    "        # rankers here are the indices of the column selected\n",
    "        # at each iteration to maximize the performance score\n",
    "        self.rankers_ = np.empty(n_rounds, dtype = np.int32)\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: Union[pd.DataFrame, pd.Series]):\n",
    "        def rank_by_feature(X: pd.DataFrame):\n",
    "            return X.reset_index(drop = True).sort_values().reset_index().sort_values('index').index\n",
    "        # number of queries in the dataset\n",
    "        self.n_queries_ = len(X.groupby('query').groups)\n",
    "        # features (minus query column)\n",
    "        n_features = X.shape[1] - 1\n",
    "        # distribution coefficients for weighting queries' importances (sum up to 1)\n",
    "        distributions = np.ones(self.n_queries_, dtype = np.float32) / self.n_queries_\n",
    "        # (query-index, document-indices) dictionary\n",
    "        query_groups = X.groupby('query').groups\n",
    "        # true relevance labels of each document for each query\n",
    "        targets = [ y.iloc[indices].tolist() for indices in query_groups.values() ]\n",
    "        # final boosting (additive) criterion for each query (used for ranking)\n",
    "        criterion = [ np.zeros(len(indices)) for indices in query_groups.values() ]\n",
    "        # iterations\n",
    "        for t in range(self.n_rounds):\n",
    "            # search feature that maximizes the score\n",
    "            max_score = -np.inf\n",
    "            argmax_feature = None\n",
    "            argmax_scores = None\n",
    "            # compute score for each one\n",
    "            for k in range(1, 1 + n_features):\n",
    "                # document indices permutations (for each query)\n",
    "                permutations = [ rank_by_feature(X.iloc[indices, k]) for indices in query_groups.values() ]\n",
    "                # compute performance scores for each feature (for each query) in [-1, 1]\n",
    "                scores = 2 * np.array([ \n",
    "                        self.scorer_(\n",
    "                            [ targets[iquery] ], \n",
    "                            [ permutations[iquery] ]\n",
    "                        ) \n",
    "                        for iquery in range(self.n_queries_) \n",
    "                    ], \n",
    "                    dtype = np.float32\n",
    "                ) - 1\n",
    "                # aggregate scores over the query\n",
    "                score = np.dot(scores, distributions)\n",
    "                # update if better\n",
    "                if score > max_score:\n",
    "                    max_score = score\n",
    "                    argmax_feature = k\n",
    "                    argmax_scores = scores\n",
    "            # ranker column index at current iteration\n",
    "            self.rankers_[t] = argmax_feature\n",
    "            # compute alpha for current iteration\n",
    "            self.alphas_[t] = 0.5 * np.log(np.dot(distributions, 1 + argmax_scores) / np.dot(distributions, 1 - argmax_scores))\n",
    "            # update boosting criterion\n",
    "            for iquery in range(self.n_queries_):\n",
    "                criterion[iquery] += self.alphas_[t] * X.iloc[query_groups[iquery], self.rankers_[t]]\n",
    "            # recompute performance scores with boosting criterion\n",
    "            scores = 2 * np.array([ \n",
    "                    self.scorer_(\n",
    "                        [ targets[iquery] ],\n",
    "                        [ rank_by_feature(criterion[iquery]) ]\n",
    "                    )\n",
    "                    for iquery in range(self.n_queries_) \n",
    "                ],\n",
    "                dtype = np.float32\n",
    "            ) - 1\n",
    "            # update distribution weights\n",
    "            distributions = np.exp(-scores) / np.sum(np.exp(-scores))\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        outputs = []\n",
    "        query_groups = X.groupby('query').groups\n",
    "        criterion = [ np.zeros(len(indices)) for indices in query_groups.values() ]\n",
    "        n_ranked = 0\n",
    "        # compute boosting criterion with alphas and rankers (best columns) for each iteration\n",
    "        for alpha, ranker in zip(self.alphas_, self.rankers_):\n",
    "            for iquery, indices in query_groups.items():\n",
    "                criterion[iquery] += alpha * X.iloc[indices, ranker]\n",
    "        # within each query sort the documents\n",
    "        for iquery, indices in query_groups.items():\n",
    "            ranking = pd.DataFrame({ 'query': iquery, 'document': n_ranked + np.argsort(criterion[iquery]) })\n",
    "            n_ranked += len(ranking)\n",
    "            outputs.append(ranking)\n",
    "        # concatenate all sorted indices (by relevance) in one unique frame\n",
    "        return pd.concat(outputs, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Usage\n",
    "\n",
    "Before feeding our design matrix to AdaRank, we scale features using common standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized transformed features in [-1, 1] with 0 standard deviation\n",
    "features.iloc[:, 1:] = StandardScaler().fit_transform(features.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train the model and we emit the ranking of documents (with respect to original indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query  document\n",
       "0        0        45\n",
       "1        0        16\n",
       "2        0        28\n",
       "3        0        43\n",
       "4        0        31\n",
       "..     ...       ...\n",
       "196      2       177\n",
       "197      2       169\n",
       "198      2       141\n",
       "199      2       198\n",
       "200      2       138\n",
       "\n",
       "[201 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AdaRank()\n",
    "# train the model on ground truth labels\n",
    "model.fit(features, labels)\n",
    "# emit the ranking\n",
    "ranking = model.transform(features)\n",
    "ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how documents appear sorted with respect to the query index according to our implementation of AdaRank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>component</th>\n",
       "      <th>system</th>\n",
       "      <th>property</th>\n",
       "      <th>loinc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0</td>\n",
       "      <td>Hepatitis B virus DNA [#/volume] (viral load) ...</td>\n",
       "      <td>Hepatitis B virus DNA</td>\n",
       "      <td>Ser</td>\n",
       "      <td>NCnc</td>\n",
       "      <td>20442-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>Methicillin resistant Staphylococcus aureus [P...</td>\n",
       "      <td>Staphylococcus aureus.methicillin resistant is...</td>\n",
       "      <td>XXX</td>\n",
       "      <td>ACnc</td>\n",
       "      <td>13317-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0</td>\n",
       "      <td>Glucose [Moles/volume] in Serum or Plasma --3 ...</td>\n",
       "      <td>Glucose^3H post 100 g glucose PO</td>\n",
       "      <td>Ser/Plas</td>\n",
       "      <td>SCnc</td>\n",
       "      <td>14764-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0</td>\n",
       "      <td>C reactive protein [Mass/volume] in Serum or P...</td>\n",
       "      <td>C reactive protein</td>\n",
       "      <td>Ser/Plas</td>\n",
       "      <td>MCnc</td>\n",
       "      <td>30522-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0</td>\n",
       "      <td>Indirect antiglobulin test.complement specific...</td>\n",
       "      <td>Indirect antiglobulin test.complement specific...</td>\n",
       "      <td>Ser/Plas</td>\n",
       "      <td>ACnc</td>\n",
       "      <td>1003-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>2</td>\n",
       "      <td>Ciprofloxacin [Susceptibility]</td>\n",
       "      <td>Ciprofloxacin</td>\n",
       "      <td>Isolate</td>\n",
       "      <td>Susc</td>\n",
       "      <td>18906-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>2</td>\n",
       "      <td>Nitrofurantoin [Susceptibility]</td>\n",
       "      <td>Nitrofurantoin</td>\n",
       "      <td>Isolate</td>\n",
       "      <td>Susc</td>\n",
       "      <td>18955-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>2</td>\n",
       "      <td>Cefazolin [Susceptibility]</td>\n",
       "      <td>Cefazolin</td>\n",
       "      <td>Isolate</td>\n",
       "      <td>Susc</td>\n",
       "      <td>18878-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2</td>\n",
       "      <td>Ampicillin [Susceptibility]</td>\n",
       "      <td>Ampicillin</td>\n",
       "      <td>Isolate</td>\n",
       "      <td>Susc</td>\n",
       "      <td>18864-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>2</td>\n",
       "      <td>Vancomycin [Susceptibility]</td>\n",
       "      <td>Vancomycin</td>\n",
       "      <td>Isolate</td>\n",
       "      <td>Susc</td>\n",
       "      <td>19000-9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query                                               text  \\\n",
       "45       0  Hepatitis B virus DNA [#/volume] (viral load) ...   \n",
       "16       0  Methicillin resistant Staphylococcus aureus [P...   \n",
       "28       0  Glucose [Moles/volume] in Serum or Plasma --3 ...   \n",
       "43       0  C reactive protein [Mass/volume] in Serum or P...   \n",
       "31       0  Indirect antiglobulin test.complement specific...   \n",
       "..     ...                                                ...   \n",
       "177      2                     Ciprofloxacin [Susceptibility]   \n",
       "169      2                    Nitrofurantoin [Susceptibility]   \n",
       "141      2                         Cefazolin [Susceptibility]   \n",
       "198      2                        Ampicillin [Susceptibility]   \n",
       "138      2                        Vancomycin [Susceptibility]   \n",
       "\n",
       "                                             component    system property  \\\n",
       "45                               Hepatitis B virus DNA       Ser     NCnc   \n",
       "16   Staphylococcus aureus.methicillin resistant is...       XXX     ACnc   \n",
       "28                    Glucose^3H post 100 g glucose PO  Ser/Plas     SCnc   \n",
       "43                                  C reactive protein  Ser/Plas     MCnc   \n",
       "31   Indirect antiglobulin test.complement specific...  Ser/Plas     ACnc   \n",
       "..                                                 ...       ...      ...   \n",
       "177                                      Ciprofloxacin   Isolate     Susc   \n",
       "169                                     Nitrofurantoin   Isolate     Susc   \n",
       "141                                          Cefazolin   Isolate     Susc   \n",
       "198                                         Ampicillin   Isolate     Susc   \n",
       "138                                         Vancomycin   Isolate     Susc   \n",
       "\n",
       "       loinc  \n",
       "45   20442-0  \n",
       "16   13317-3  \n",
       "28   14764-5  \n",
       "43   30522-7  \n",
       "31    1003-3  \n",
       "..       ...  \n",
       "177  18906-8  \n",
       "169  18955-5  \n",
       "141  18878-9  \n",
       "198  18864-9  \n",
       "138  19000-9  \n",
       "\n",
       "[201 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked = documents.iloc[ranking['document'], :]\n",
    "ranked.insert(0, 'query', ranking['query'])\n",
    "ranked"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
