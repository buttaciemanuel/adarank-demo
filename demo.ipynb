{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaRank implementation\n",
    "\n",
    "In this notebook we show a simple and effective implementation of AdaRank algorithm from paper [AdaRank: a boosting algorithm for information retrieval](https://dl.acm.org/doi/abs/10.1145/1277741.1277809?casa_token=ku7AGgHMiTsAAAAA:sm_rUCTguz9F5k2yANn2iLGLVwBFpMkQOB_zN9csd7zCH5mDSYBFOToYoQmP5ChVbOUidtZWFFgZxw) for listwise ranking of documents with respect to queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialization\n",
    "\n",
    "In this first part we setup the libraries installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (2.1.1)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (1.26.0)\n",
      "Collecting sklearn\n",
      "  Using cached sklearn-0.0.post10.tar.gz (3.6 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[18 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The 'sklearn' PyPI package is deprecated, use 'scikit-learn'\n",
      "  \u001b[31m   \u001b[0m rather than 'sklearn' for pip commands.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Here is how to fix this error in the main use cases:\n",
      "  \u001b[31m   \u001b[0m - use 'pip install scikit-learn' rather than 'pip install sklearn'\n",
      "  \u001b[31m   \u001b[0m - replace 'sklearn' by 'scikit-learn' in your pip requirements files\n",
      "  \u001b[31m   \u001b[0m   (requirements.txt, setup.py, setup.cfg, Pipfile, etc ...)\n",
      "  \u001b[31m   \u001b[0m - if the 'sklearn' package is used by one of your dependencies,\n",
      "  \u001b[31m   \u001b[0m   it would be great if you take some time to track which package uses\n",
      "  \u001b[31m   \u001b[0m   'sklearn' instead of 'scikit-learn' and report it to their issue tracker\n",
      "  \u001b[31m   \u001b[0m - as a last resort, set the environment variable\n",
      "  \u001b[31m   \u001b[0m   SKLEARN_ALLOW_DEPRECATED_SKLEARN_PACKAGE_INSTALL=True to avoid this error\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m More information is available at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m If the previous advice does not cover your use case, feel free to report it at\n",
      "  \u001b[31m   \u001b[0m https://github.com/scikit-learn/sklearn-pypi-package/issues/new\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
      "\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we convert the raw csv dataset files into the expected format for the AdaRank algorithm. We choose to create a file of index pairs for (query, document) in order to avoid the redundancy given by queries and documents text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>document</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2</td>\n",
       "      <td>196</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2</td>\n",
       "      <td>197</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2</td>\n",
       "      <td>198</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2</td>\n",
       "      <td>199</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query  document  rank\n",
       "0        0         0   100\n",
       "1        0         1    64\n",
       "2        0         2    33\n",
       "3        0         3    45\n",
       "4        0         4    90\n",
       "..     ...       ...   ...\n",
       "196      2       196    16\n",
       "197      2       197    83\n",
       "198      2       198    18\n",
       "199      2       199    67\n",
       "200      2       200    90\n",
       "\n",
       "[201 rows x 3 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of document datasets for each query\n",
    "documents = []\n",
    "# list of queries\n",
    "queries = []\n",
    "# list of datasets of pair (query, document) with a random relevance score in [0, 100)\n",
    "pairs = []\n",
    "# progessive indices used to keep count\n",
    "dindex, qindex = 0, 0\n",
    "# each raw dataset is used to embody its data in a new format\n",
    "for file in os.listdir('raw'):\n",
    "    frame = pd.read_csv(os.path.join('raw', file), sep = ';')\n",
    "    query = file.removesuffix('.csv')\n",
    "    # easy re-naming\n",
    "    frame.rename(columns = { 'long_common_name': 'text', 'loinc_num': 'loinc' }, inplace = True)\n",
    "    # insert query and related documents\n",
    "    queries.append(query)\n",
    "    documents.append(frame)\n",
    "    # we insert (query-index, document-index, random relevance score) for each document retrieved in the query\n",
    "    pairs.extend([ (qindex, dindex + d, random.randint(0, 100)) for d in range(len(frame)) ])\n",
    "    # progressive update of indices\n",
    "    dindex += len(frame)\n",
    "    qindex += 1\n",
    "# concatenation among all queries of the documents\n",
    "documents = pd.concat(documents, axis = 0, ignore_index = True)\n",
    "loinc = documents['loinc']\n",
    "documents.drop(columns = 'loinc', inplace = True)\n",
    "documents['loinc'] = loinc\n",
    "documents.to_csv('data/documents.csv', sep = ',', index_label = 'document')\n",
    "# concatenation of all queries\n",
    "queries = pd.DataFrame({ 'text': queries })\n",
    "queries.to_csv('data/queries.csv', sep = ',', index_label = 'query')\n",
    "# concatenation of all pairs with relevance scores in a new file\n",
    "pairs = pd.DataFrame(pairs, columns=[ 'query', 'document', 'rank' ])\n",
    "pairs.to_csv('data/pairs.csv', sep = ',')\n",
    "\n",
    "pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature extraction\n",
    "\n",
    "For our feature extraction mecahnism we combine each document and query by extracting three features.\n",
    "\n",
    "| Feature | Computation |\n",
    "|-|-|\n",
    "| log-frecency sum | $\\sum_{\\forall w_j \\, \\in \\, d \\, \\cup \\, q} \\log(1 + \\text{count}(w_j, d)) $ |\n",
    "| log-frecency sum | $\\sum_{\\forall w_j \\, \\in \\, d \\, \\cup \\, q} \\log(\\text{tf-idf}(w_j, d)) $ |\n",
    "| log-inverse-frequency sum | $\\sum_{\\forall w_j \\, \\in \\, d \\, \\cup \\, q} \\log(1 + 1 / (1 + \\text{count}(w_j, d))) $ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>log-frecency</th>\n",
       "      <th>tf-idf</th>\n",
       "      <th>log-inverse-frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4.158883</td>\n",
       "      <td>2.261813</td>\n",
       "      <td>77.292686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>1.844363</td>\n",
       "      <td>77.868050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.686473</td>\n",
       "      <td>78.155732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.697418</td>\n",
       "      <td>78.155732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4.158883</td>\n",
       "      <td>2.335105</td>\n",
       "      <td>77.292686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.569326</td>\n",
       "      <td>79.542027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>79.542027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.390079</td>\n",
       "      <td>79.829709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2</td>\n",
       "      <td>4.852030</td>\n",
       "      <td>2.465639</td>\n",
       "      <td>78.391298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2</td>\n",
       "      <td>2.079442</td>\n",
       "      <td>1.701545</td>\n",
       "      <td>79.542027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query  log-frecency    tf-idf  log-inverse-frequency\n",
       "0        0      4.158883  2.261813              77.292686\n",
       "1        0      2.772589  1.844363              77.868050\n",
       "2        0      2.079442  1.686473              78.155732\n",
       "3        0      2.079442  1.697418              78.155732\n",
       "4        0      4.158883  2.335105              77.292686\n",
       "..     ...           ...       ...                    ...\n",
       "196      2      2.079442  1.569326              79.542027\n",
       "197      2      2.079442  1.732051              79.542027\n",
       "198      2      1.386294  1.390079              79.829709\n",
       "199      2      4.852030  2.465639              78.391298\n",
       "200      2      2.079442  1.701545              79.542027\n",
       "\n",
       "[201 rows x 4 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = None\n",
    "labels = None\n",
    "queries_words = queries['text'].astype('string').str.lower().str.split()\n",
    "# we build vocabularies and features\n",
    "for query, indices in pairs.groupby('query').groups.items():\n",
    "    # we select documents text for current query\n",
    "    documents_selected = documents.loc[pairs.loc[indices, 'document'], 'text']\n",
    "    # and all the tokenized words\n",
    "    documents_words = TfidfVectorizer(stop_words = 'english', binary = False).fit(documents_selected).get_feature_names_out()\n",
    "    # to such vocabulary we add tokens from the query's text\n",
    "    vocabulary = set(documents_words.tolist()).union(queries_words.iloc[query])\n",
    "    # we build the design matrix for current query with all fancy features\n",
    "    matrix = pd.DataFrame({\n",
    "        'query': query,\n",
    "        'log-frecency': pd.DataFrame(\n",
    "            CountVectorizer(stop_words = 'english', binary = False, vocabulary = vocabulary).fit_transform(documents_selected).todense()\n",
    "        ).apply(lambda x: np.log(1 + x)).sum(axis = 1),\n",
    "        'tf-idf': pd.DataFrame(\n",
    "            TfidfVectorizer(stop_words = 'english', binary = False, use_idf = True, vocabulary = vocabulary).fit_transform(documents_selected).todense(), \n",
    "        ).sum(axis = 1),\n",
    "        'log-inverse-frequency': pd.DataFrame(\n",
    "            CountVectorizer(stop_words = 'english', binary = False, vocabulary = vocabulary).fit_transform(documents_selected).todense()\n",
    "        ).apply(lambda x: np.log(1 + 1 / (1 + x))).sum(axis = 1),\n",
    "    })\n",
    "    # we concatenate each feature matrix\n",
    "    if features is None:\n",
    "        features = matrix\n",
    "    else:\n",
    "        features = pd.concat([ features, matrix ], axis = 0, ignore_index = True)\n",
    "    # we concatenate each label vector\n",
    "    if labels is None:\n",
    "        labels = pairs.loc[indices, 'rank']\n",
    "    else:\n",
    "        labels = pd.concat([ labels, pairs.loc[indices, 'rank'] ], axis = 0, ignore_index = True)\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. AdaRank implementation\n",
    "\n",
    "For our implementation we follow the explanation from the paper and we extend Scikit-Learn base class. Besides, we use NDCG score for evaluating the performance of weak rankers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaRank(BaseEstimator):\n",
    "\n",
    "    def __init__(self, n_rounds: int = 10, metric: str = 'ndcg') -> None:\n",
    "        super().__init__()\n",
    "        # number of training rounds\n",
    "        self.n_rounds = n_rounds\n",
    "        # performance metrics, by default NDCG\n",
    "        self.scorer_ = ndcg_score if metric else None\n",
    "        # alphas coefficients for weighting rankers' importances\n",
    "        self.alphas_ = np.empty(n_rounds, dtype = np.float32)\n",
    "        # rankers here are the indices of the column selected\n",
    "        # at each iteration to maximize the performance score\n",
    "        self.rankers_ = np.empty(n_rounds, dtype = np.int32)\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: Union[pd.DataFrame, pd.Series]):\n",
    "        def rank_by_feature(X: pd.DataFrame):\n",
    "            return X.reset_index(drop = True).sort_values().reset_index().sort_values('index').index\n",
    "        # number of queries in the dataset\n",
    "        self.n_queries_ = len(X.groupby('query').groups)\n",
    "        # features (minus query column)\n",
    "        n_features = X.shape[1] - 1\n",
    "        # distribution coefficients for weighting queries' importances (sum up to 1)\n",
    "        distributions = np.ones(self.n_queries_, dtype = np.float32) / self.n_queries_\n",
    "        # (query-index, document-indices) dictionary\n",
    "        query_groups = X.groupby('query').groups\n",
    "        # true relevance labels of each document for each query\n",
    "        targets = [ y.iloc[indices].tolist() for indices in query_groups.values() ]\n",
    "        # final boosting (additive) criterion for each query (used for ranking)\n",
    "        criterion = [ np.zeros(len(indices)) for indices in query_groups.values() ]\n",
    "        # iterations\n",
    "        for t in range(self.n_rounds):\n",
    "            # search feature that maximizes the score\n",
    "            max_score = -np.inf\n",
    "            argmax_feature = None\n",
    "            argmax_scores = None\n",
    "            # compute score for each one\n",
    "            for k in range(1, 1 + n_features):\n",
    "                # document indices permutations (for each query)\n",
    "                permutations = [ rank_by_feature(X.iloc[indices, k]) for indices in query_groups.values() ]\n",
    "                # compute performance scores for each feature (for each query) in [-1, 1]\n",
    "                scores = 2 * np.array([ \n",
    "                        self.scorer_(\n",
    "                            [ targets[iquery] ], \n",
    "                            [ permutations[iquery] ]\n",
    "                        ) \n",
    "                        for iquery in range(self.n_queries_) \n",
    "                    ], \n",
    "                    dtype = np.float32\n",
    "                ) - 1\n",
    "                # aggregate scores over the query\n",
    "                score = np.dot(scores, distributions)\n",
    "                # update if better\n",
    "                if score > max_score:\n",
    "                    max_score = score\n",
    "                    argmax_feature = k\n",
    "                    argmax_scores = scores\n",
    "            # ranker column index at current iteration\n",
    "            self.rankers_[t] = argmax_feature\n",
    "            # compute alpha for current iteration\n",
    "            self.alphas_[t] = 0.5 * np.log(np.dot(distributions, 1 + argmax_scores) / np.dot(distributions, 1 - argmax_scores))\n",
    "            # update boosting criterion\n",
    "            for iquery in range(self.n_queries_):\n",
    "                criterion[iquery] += self.alphas_[t] * X.iloc[query_groups[iquery], self.rankers_[t]]\n",
    "            # recompute performance scores with boosting criterion\n",
    "            scores = 2 * np.array([ \n",
    "                    self.scorer_(\n",
    "                        [ targets[iquery] ],\n",
    "                        [ rank_by_feature(criterion[iquery]) ]\n",
    "                    )\n",
    "                    for iquery in range(self.n_queries_) \n",
    "                ],\n",
    "                dtype = np.float32\n",
    "            ) - 1\n",
    "            # update distribution weights\n",
    "            distributions = np.exp(-scores) / np.sum(np.exp(-scores))\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        outputs = []\n",
    "        query_groups = X.groupby('query').groups\n",
    "        criterion = [ np.zeros(len(indices)) for indices in query_groups.values() ]\n",
    "        n_ranked = 0\n",
    "        # compute boosting criterion with alphas and rankers (best columns) for each iteration\n",
    "        for alpha, ranker in zip(self.alphas_, self.rankers_):\n",
    "            for iquery, indices in query_groups.items():\n",
    "                criterion[iquery] += alpha * X.iloc[indices, ranker]\n",
    "        # within each query sort the documents\n",
    "        for iquery, indices in query_groups.items():\n",
    "            ranking = pd.DataFrame({ 'query': iquery, 'document': n_ranked + np.argsort(criterion[iquery]) })\n",
    "            n_ranked += len(ranking)\n",
    "            outputs.append(ranking)\n",
    "        # concatenate all sorted indices (by relevance) in one unique frame\n",
    "        return pd.concat(outputs, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Usage\n",
    "\n",
    "Before feeding our design matrix to AdaRank, we scale features using common standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized transformed features in [-1, 1] with 0 standard deviation\n",
    "features.iloc[:, 1:] = StandardScaler().fit_transform(features.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train the model and we emit the ranking of documents (with respect to original indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query  document\n",
       "0        0        66\n",
       "1        0        64\n",
       "2        0        63\n",
       "3        0        60\n",
       "4        0        51\n",
       "..     ...       ...\n",
       "196      2       173\n",
       "197      2       190\n",
       "198      2       187\n",
       "199      2       142\n",
       "200      2       144\n",
       "\n",
       "[201 rows x 2 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AdaRank()\n",
    "# train the model on ground truth labels\n",
    "model.fit(features, labels)\n",
    "# emit the ranking\n",
    "ranking = model.transform(features)\n",
    "ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how documents appear sorted with respect to the query index according to our implementation of AdaRank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>text</th>\n",
       "      <th>component</th>\n",
       "      <th>system</th>\n",
       "      <th>property</th>\n",
       "      <th>loinc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>Other Antibiotic [Susceptibility]</td>\n",
       "      <td>Antibiotic XXX</td>\n",
       "      <td>Isolate</td>\n",
       "      <td>Susc</td>\n",
       "      <td>23658-8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0</td>\n",
       "      <td>Gentamicin [Susceptibility]</td>\n",
       "      <td>Gentamicin</td>\n",
       "      <td>Isolate</td>\n",
       "      <td>Susc</td>\n",
       "      <td>18928-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0</td>\n",
       "      <td>Cefazolin [Susceptibility]</td>\n",
       "      <td>Cefazolin</td>\n",
       "      <td>Isolate</td>\n",
       "      <td>Susc</td>\n",
       "      <td>18878-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0</td>\n",
       "      <td>Levofloxacin [Susceptibility]</td>\n",
       "      <td>Levofloxacin</td>\n",
       "      <td>Isolate</td>\n",
       "      <td>Susc</td>\n",
       "      <td>20629-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>Vancomycin [Susceptibility]</td>\n",
       "      <td>Vancomycin</td>\n",
       "      <td>Isolate</td>\n",
       "      <td>Susc</td>\n",
       "      <td>19000-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2</td>\n",
       "      <td>Glucose [Moles/volume] in Serum or Plasma --3 ...</td>\n",
       "      <td>Glucose^3H post 100 g glucose PO</td>\n",
       "      <td>Ser/Plas</td>\n",
       "      <td>SCnc</td>\n",
       "      <td>14764-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>2</td>\n",
       "      <td>C reactive protein [Mass/volume] in Serum or P...</td>\n",
       "      <td>C reactive protein</td>\n",
       "      <td>Ser/Plas</td>\n",
       "      <td>MCnc</td>\n",
       "      <td>30522-7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>2</td>\n",
       "      <td>Indirect antiglobulin test.complement specific...</td>\n",
       "      <td>Indirect antiglobulin test.complement specific...</td>\n",
       "      <td>Ser/Plas</td>\n",
       "      <td>ACnc</td>\n",
       "      <td>1003-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>2</td>\n",
       "      <td>Hepatitis B virus DNA [#/volume] (viral load) ...</td>\n",
       "      <td>Hepatitis B virus DNA</td>\n",
       "      <td>Ser</td>\n",
       "      <td>NCnc</td>\n",
       "      <td>20442-0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>2</td>\n",
       "      <td>Methicillin resistant Staphylococcus aureus [P...</td>\n",
       "      <td>Staphylococcus aureus.methicillin resistant is...</td>\n",
       "      <td>XXX</td>\n",
       "      <td>ACnc</td>\n",
       "      <td>13317-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query                                               text  \\\n",
       "66       0                  Other Antibiotic [Susceptibility]   \n",
       "64       0                        Gentamicin [Susceptibility]   \n",
       "63       0                         Cefazolin [Susceptibility]   \n",
       "60       0                      Levofloxacin [Susceptibility]   \n",
       "51       0                        Vancomycin [Susceptibility]   \n",
       "..     ...                                                ...   \n",
       "173      2  Glucose [Moles/volume] in Serum or Plasma --3 ...   \n",
       "190      2  C reactive protein [Mass/volume] in Serum or P...   \n",
       "187      2  Indirect antiglobulin test.complement specific...   \n",
       "142      2  Hepatitis B virus DNA [#/volume] (viral load) ...   \n",
       "144      2  Methicillin resistant Staphylococcus aureus [P...   \n",
       "\n",
       "                                             component    system property  \\\n",
       "66                                      Antibiotic XXX   Isolate     Susc   \n",
       "64                                          Gentamicin   Isolate     Susc   \n",
       "63                                           Cefazolin   Isolate     Susc   \n",
       "60                                        Levofloxacin   Isolate     Susc   \n",
       "51                                          Vancomycin   Isolate     Susc   \n",
       "..                                                 ...       ...      ...   \n",
       "173                   Glucose^3H post 100 g glucose PO  Ser/Plas     SCnc   \n",
       "190                                 C reactive protein  Ser/Plas     MCnc   \n",
       "187  Indirect antiglobulin test.complement specific...  Ser/Plas     ACnc   \n",
       "142                              Hepatitis B virus DNA       Ser     NCnc   \n",
       "144  Staphylococcus aureus.methicillin resistant is...       XXX     ACnc   \n",
       "\n",
       "       loinc  \n",
       "66   23658-8  \n",
       "64   18928-2  \n",
       "63   18878-9  \n",
       "60   20629-2  \n",
       "51   19000-9  \n",
       "..       ...  \n",
       "173  14764-5  \n",
       "190  30522-7  \n",
       "187   1003-3  \n",
       "142  20442-0  \n",
       "144  13317-3  \n",
       "\n",
       "[201 rows x 6 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranked = documents.iloc[ranking['document'], :]\n",
    "ranked.insert(0, 'query', ranking['query'])\n",
    "ranked"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
