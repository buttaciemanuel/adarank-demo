{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AdaRank implementation\n",
    "\n",
    "In this notebook we show a simple and effective implementation of AdaRank algorithm from paper [AdaRank: a boosting algorithm for information retrieval](https://dl.acm.org/doi/abs/10.1145/1277741.1277809?casa_token=ku7AGgHMiTsAAAAA:sm_rUCTguz9F5k2yANn2iLGLVwBFpMkQOB_zN9csd7zCH5mDSYBFOToYoQmP5ChVbOUidtZWFFgZxw) for listwise ranking of documents with respect to queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialization\n",
    "\n",
    "In this first part we setup the libraries installation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas numpy sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.base import BaseEstimator\n",
    "from typing import Union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we convert the raw csv dataset files into the expected format for the AdaRank algorithm. We choose to create a file of index pairs for (query, document) in order to avoid the redundancy given by queries and documents text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2</td>\n",
       "      <td>63</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2</td>\n",
       "      <td>65</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query  document  label\n",
       "0        0         0     25\n",
       "1        0         1     60\n",
       "2        0         2     21\n",
       "3        0         3     66\n",
       "4        0         4     24\n",
       "..     ...       ...    ...\n",
       "196      2        62     58\n",
       "197      2        63     35\n",
       "198      2        64     57\n",
       "199      2        65     14\n",
       "200      2        66     34\n",
       "\n",
       "[201 rows x 3 columns]"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of document datasets for each query\n",
    "documents = []\n",
    "# list of queries\n",
    "queries = []\n",
    "# list of datasets of pair (query, document) with a random relevance score in [0, 100)\n",
    "pairs = []\n",
    "# progessive indices used to keep count\n",
    "dindex, qindex = 0, 0\n",
    "# each raw dataset is used to embody its data in a new format\n",
    "for file in os.listdir('raw'):\n",
    "    frame = pd.read_csv(os.path.join('raw', file), sep = ',')\n",
    "    query = file.removesuffix('.csv').replace('_', ' ')\n",
    "    # insert query and related documents\n",
    "    queries.append(query)\n",
    "    documents.append(frame.drop(columns = [ 'label' ]))\n",
    "    # we insert (query-index, document-index, random relevance score) for each document retrieved in the query\n",
    "    pairs.extend([ (qindex, dindex + d, row.label) for d, row in enumerate(frame.itertuples()) ])\n",
    "    # progressive update of indices\n",
    "    qindex += 1\n",
    "# concatenation among all queries of the documents\n",
    "documents = pd.concat(documents, axis = 0, ignore_index = True)\n",
    "documents.to_csv('data/documents.csv', sep = ',')\n",
    "# concatenation of all queries\n",
    "queries = pd.DataFrame({ 'text': queries })\n",
    "queries.to_csv('data/queries.csv', sep = ',', index_label = 'query')\n",
    "# concatenation of all pairs with relevance scores in a new file\n",
    "pairs = pd.DataFrame(pairs, columns = [ 'query', 'document', 'label' ])\n",
    "pairs.to_csv('data/pairs.csv', sep = ',')\n",
    "\n",
    "pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature extraction\n",
    "\n",
    "For our feature extraction mecahnism we combine each document and query by extracting three features.\n",
    "\n",
    "| Feature                   | Computation                                                                             |\n",
    "|---------------------------|-----------------------------------------------------------------------------------------|\n",
    "| log-frecency sum          | $\\sum_{\\forall w_j \\, \\in \\, d \\, \\cup \\, q} \\log(1 + \\text{count}(w_j, d)) $           |\n",
    "| log-frecency sum          | $\\sum_{\\forall w_j \\, \\in \\, d \\, \\cup \\, q} \\log(\\text{tf-idf}(w_j, d)) $              |\n",
    "| log-inverse-frequency sum | $\\sum_{\\forall w_j \\, \\in \\, d \\, \\cup \\, q} \\log(1 + 1 / (1 + \\text{count}(w_j, d))) $ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>log-frecency</th>\n",
       "      <th>tf-idf</th>\n",
       "      <th>log-inverse-frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>1.947576</td>\n",
       "      <td>77.868050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>4.852030</td>\n",
       "      <td>2.465639</td>\n",
       "      <td>77.005004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4.158883</td>\n",
       "      <td>2.325861</td>\n",
       "      <td>77.292686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2.772589</td>\n",
       "      <td>1.844363</td>\n",
       "      <td>77.868050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>1.377624</td>\n",
       "      <td>78.443414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2</td>\n",
       "      <td>4.852030</td>\n",
       "      <td>2.465639</td>\n",
       "      <td>78.391298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2</td>\n",
       "      <td>4.158883</td>\n",
       "      <td>2.226099</td>\n",
       "      <td>78.678981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2</td>\n",
       "      <td>4.158883</td>\n",
       "      <td>2.283433</td>\n",
       "      <td>78.678981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2</td>\n",
       "      <td>3.465736</td>\n",
       "      <td>2.224207</td>\n",
       "      <td>78.966663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2</td>\n",
       "      <td>4.158883</td>\n",
       "      <td>2.261813</td>\n",
       "      <td>78.678981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query  log-frecency    tf-idf  log-inverse-frequency\n",
       "0        0      2.772589  1.947576              77.868050\n",
       "1        0      4.852030  2.465639              77.005004\n",
       "2        0      4.158883  2.325861              77.292686\n",
       "3        0      2.772589  1.844363              77.868050\n",
       "4        0      1.386294  1.377624              78.443414\n",
       "..     ...           ...       ...                    ...\n",
       "196      2      4.852030  2.465639              78.391298\n",
       "197      2      4.158883  2.226099              78.678981\n",
       "198      2      4.158883  2.283433              78.678981\n",
       "199      2      3.465736  2.224207              78.966663\n",
       "200      2      4.158883  2.261813              78.678981\n",
       "\n",
       "[201 rows x 4 columns]"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = None\n",
    "labels = None\n",
    "queries_words = queries['text'].astype('string').str.lower().str.split()\n",
    "# we build vocabularies and features\n",
    "for query, indices in pairs.groupby('query').groups.items():\n",
    "    # we select documents text for current query\n",
    "    # documents_selected = documents.loc[pairs.loc[indices, 'document'], 'name']\n",
    "    documents_selected = documents.loc[pairs.loc[indices, 'document'], 'name']\n",
    "    # and all the tokenized words\n",
    "    documents_words = TfidfVectorizer(stop_words = 'english', binary = False).fit(documents_selected).get_feature_names_out()\n",
    "    # to such vocabulary we add tokens from the query's text\n",
    "    vocabulary = set(documents_words.tolist()).union(queries_words.iloc[query])\n",
    "    # we build the design matrix for current query with all fancy features\n",
    "    matrix = pd.DataFrame({\n",
    "        'query': query,\n",
    "        'log-frecency': pd.DataFrame(\n",
    "            CountVectorizer(stop_words = 'english', binary = False, vocabulary = vocabulary).fit_transform(documents_selected).todense()\n",
    "        ).apply(lambda x: np.log(1 + x)).sum(axis = 1),\n",
    "        'tf-idf': pd.DataFrame(\n",
    "            TfidfVectorizer(stop_words = 'english', binary = False, use_idf = True, vocabulary = vocabulary).fit_transform(documents_selected).todense(), \n",
    "        ).sum(axis = 1),\n",
    "        'log-inverse-frequency': pd.DataFrame(\n",
    "            CountVectorizer(stop_words = 'english', binary = False, vocabulary = vocabulary).fit_transform(documents_selected).todense()\n",
    "        ).apply(lambda x: np.log(1 + 1 / (1 + x))).sum(axis = 1),\n",
    "    })\n",
    "    # we concatenate each feature matrix\n",
    "    if features is None:\n",
    "        features = matrix\n",
    "    else:\n",
    "        features = pd.concat([ features, matrix ], axis = 0, ignore_index = True)\n",
    "    # we concatenate each label vector\n",
    "    if labels is None:\n",
    "        labels = pairs.loc[indices, 'label']\n",
    "    else:\n",
    "        labels = pd.concat([ labels, pairs.loc[indices, 'label'] ], axis = 0, ignore_index = True)\n",
    "\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. AdaRank implementation\n",
    "\n",
    "For our implementation we follow the explanation from the paper and we extend Scikit-Learn base class. Besides, we use NDCG score for evaluating the performance of weak rankers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaRank(BaseEstimator):\n",
    "\n",
    "    def __init__(self, n_rounds: int = 10, metric: str = 'ndcg') -> None:\n",
    "        super().__init__()\n",
    "        # number of training rounds\n",
    "        self.n_rounds = n_rounds\n",
    "        # performance metrics, by default NDCG\n",
    "        self.scorer_ = ndcg_score if metric else None\n",
    "        # alphas coefficients for weighting rankers' importances\n",
    "        self.alphas_ = np.empty(n_rounds, dtype = np.float32)\n",
    "        # rankers here are the indices of the column selected\n",
    "        # at each iteration to maximize the performance score\n",
    "        self.rankers_ = np.empty(n_rounds, dtype = np.int32)\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y: Union[pd.DataFrame, pd.Series]):\n",
    "        def rank_by_feature(X: pd.DataFrame):\n",
    "            return X.reset_index(drop = True).sort_values().reset_index().sort_values('index').index\n",
    "        # number of queries in the dataset\n",
    "        self.n_queries_ = len(X.groupby('query').groups)\n",
    "        # features (minus query column)\n",
    "        n_features = X.shape[1] - 1\n",
    "        # distribution coefficients for weighting queries' importances (sum up to 1)\n",
    "        distributions = np.ones(self.n_queries_, dtype = np.float32) / self.n_queries_\n",
    "        # (query-index, document-indices) dictionary\n",
    "        query_groups = X.groupby('query').groups\n",
    "        # true relevance labels of each document for each query\n",
    "        targets = [ y.iloc[indices].tolist() for indices in query_groups.values() ]\n",
    "        # final boosting (additive) criterion for each query (used for ranking)\n",
    "        criterion = [ np.zeros(len(indices)) for indices in query_groups.values() ]\n",
    "        # iterations\n",
    "        for t in range(self.n_rounds):\n",
    "            # search feature that maximizes the score\n",
    "            max_score = -np.inf\n",
    "            argmax_feature = None\n",
    "            argmax_scores = None\n",
    "            # compute score for each one\n",
    "            for k in range(1, 1 + n_features):\n",
    "                # document indices permutations (for each query)\n",
    "                permutations = [ rank_by_feature(X.iloc[indices, k]) for indices in query_groups.values() ]\n",
    "                # compute performance scores for each feature (for each query) in [-1, 1]\n",
    "                scores = 2 * np.array([ \n",
    "                        self.scorer_(\n",
    "                            [ targets[iquery] ], \n",
    "                            [ permutations[iquery] ]\n",
    "                        ) \n",
    "                        for iquery in range(self.n_queries_) \n",
    "                    ], \n",
    "                    dtype = np.float32\n",
    "                ) - 1\n",
    "                # aggregate scores over the query\n",
    "                score = np.dot(scores, distributions)\n",
    "                # update if better\n",
    "                if score > max_score:\n",
    "                    max_score = score\n",
    "                    argmax_feature = k\n",
    "                    argmax_scores = scores\n",
    "            # ranker column index at current iteration\n",
    "            self.rankers_[t] = argmax_feature\n",
    "            # compute alpha for current iteration\n",
    "            self.alphas_[t] = 0.5 * np.log(np.dot(distributions, 1 + argmax_scores) / np.dot(distributions, 1 - argmax_scores))\n",
    "            # update boosting criterion\n",
    "            for iquery in range(self.n_queries_):\n",
    "                criterion[iquery] += self.alphas_[t] * X.iloc[query_groups[iquery], self.rankers_[t]]\n",
    "            # recompute performance scores with boosting criterion\n",
    "            scores = 2 * np.array([ \n",
    "                    self.scorer_(\n",
    "                        [ targets[iquery] ],\n",
    "                        [ rank_by_feature(criterion[iquery]) ]\n",
    "                    )\n",
    "                    for iquery in range(self.n_queries_) \n",
    "                ],\n",
    "                dtype = np.float32\n",
    "            ) - 1\n",
    "            # update distribution weights\n",
    "            distributions = np.exp(-scores) / np.sum(np.exp(-scores))\n",
    "\n",
    "    def transform(self, X, y = None):\n",
    "        outputs = []\n",
    "        query_groups = X.groupby('query').groups\n",
    "        criterion = [ np.zeros(len(indices)) for indices in query_groups.values() ]\n",
    "        n_ranked = 0\n",
    "        # compute boosting criterion with alphas and rankers (best columns) for each iteration\n",
    "        for alpha, ranker in zip(self.alphas_, self.rankers_):\n",
    "            for iquery, indices in query_groups.items():\n",
    "                criterion[iquery] += alpha * X.iloc[indices, ranker]\n",
    "        # within each query sort the documents\n",
    "        for iquery, indices in query_groups.items():\n",
    "            ranking = pd.DataFrame({ 'query': iquery, 'document': n_ranked + np.argsort(criterion[iquery]) })\n",
    "            n_ranked += len(ranking)\n",
    "            outputs.append(ranking)\n",
    "        # concatenate all sorted indices (by relevance) in one unique frame\n",
    "        return pd.concat(outputs, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Usage\n",
    "\n",
    "Before feeding our design matrix to AdaRank, we scale features using common standardization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardized transformed features in [-1, 1] with 0 standard deviation\n",
    "features.iloc[:, 1:] = StandardScaler().fit_transform(features.iloc[:, 1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we train the model and we emit the ranking of documents (with respect to original indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>2</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>2</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>2</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>201 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     query  document\n",
       "0        0        29\n",
       "1        0         6\n",
       "2        0        46\n",
       "3        0        11\n",
       "4        0        40\n",
       "..     ...       ...\n",
       "196      2       184\n",
       "197      2       172\n",
       "198      2       153\n",
       "199      2       138\n",
       "200      2       161\n",
       "\n",
       "[201 rows x 2 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AdaRank()\n",
    "# train the model on ground truth labels\n",
    "model.fit(features, labels)\n",
    "# emit the ranking\n",
    "ranking = model.transform(features)\n",
    "ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how documents appear sorted with respect to the query index according to our implementation of AdaRank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loinc</th>\n",
       "      <th>name</th>\n",
       "      <th>component</th>\n",
       "      <th>system</th>\n",
       "      <th>property</th>\n",
       "      <th>query</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20442-0</td>\n",
       "      <td>Hepatitis B virus DNA [#/volume] (viral load) ...</td>\n",
       "      <td>Hepatitis B virus DNA</td>\n",
       "      <td>Ser</td>\n",
       "      <td>NCnc</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>13317-3</td>\n",
       "      <td>Methicillin resistant Staphylococcus aureus [P...</td>\n",
       "      <td>Staphylococcus aureus.methicillin resistant is...</td>\n",
       "      <td>XXX</td>\n",
       "      <td>ACnc</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>14764-5</td>\n",
       "      <td>Glucose [Moles/volume] in Serum or Plasma --3 ...</td>\n",
       "      <td>Glucose^3H post 100 g glucose PO</td>\n",
       "      <td>Ser/Plas</td>\n",
       "      <td>SCnc</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>30522-7</td>\n",
       "      <td>C reactive protein [Mass/volume] in Serum or P...</td>\n",
       "      <td>C reactive protein</td>\n",
       "      <td>Ser/Plas</td>\n",
       "      <td>MCnc</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1003-3</td>\n",
       "      <td>Indirect antiglobulin test.complement specific...</td>\n",
       "      <td>Indirect antiglobulin test.complement specific...</td>\n",
       "      <td>Ser/Plas</td>\n",
       "      <td>ACnc</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>20629-2</td>\n",
       "      <td>Levofloxacin [Susceptibility]</td>\n",
       "      <td>Levofloxacin</td>\n",
       "      <td>Isolate</td>\n",
       "      <td>Susc</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>18928-2</td>\n",
       "      <td>Gentamicin [Susceptibility]</td>\n",
       "      <td>Gentamicin</td>\n",
       "      <td>Isolate</td>\n",
       "      <td>Susc</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19000-9</td>\n",
       "      <td>Vancomycin [Susceptibility]</td>\n",
       "      <td>Vancomycin</td>\n",
       "      <td>Isolate</td>\n",
       "      <td>Susc</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18906-8</td>\n",
       "      <td>Ciprofloxacin [Susceptibility]</td>\n",
       "      <td>Ciprofloxacin</td>\n",
       "      <td>Isolate</td>\n",
       "      <td>Susc</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>23658-8</td>\n",
       "      <td>Other Antibiotic [Susceptibility]</td>\n",
       "      <td>Antibiotic XXX</td>\n",
       "      <td>Isolate</td>\n",
       "      <td>Susc</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>67 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      loinc                                               name  \\\n",
       "29  20442-0  Hepatitis B virus DNA [#/volume] (viral load) ...   \n",
       "6   13317-3  Methicillin resistant Staphylococcus aureus [P...   \n",
       "46  14764-5  Glucose [Moles/volume] in Serum or Plasma --3 ...   \n",
       "11  30522-7  C reactive protein [Mass/volume] in Serum or P...   \n",
       "40   1003-3  Indirect antiglobulin test.complement specific...   \n",
       "..      ...                                                ...   \n",
       "50  20629-2                      Levofloxacin [Susceptibility]   \n",
       "38  18928-2                        Gentamicin [Susceptibility]   \n",
       "19  19000-9                        Vancomycin [Susceptibility]   \n",
       "4   18906-8                     Ciprofloxacin [Susceptibility]   \n",
       "27  23658-8                  Other Antibiotic [Susceptibility]   \n",
       "\n",
       "                                            component    system property  \\\n",
       "29                              Hepatitis B virus DNA       Ser     NCnc   \n",
       "6   Staphylococcus aureus.methicillin resistant is...       XXX     ACnc   \n",
       "46                   Glucose^3H post 100 g glucose PO  Ser/Plas     SCnc   \n",
       "11                                 C reactive protein  Ser/Plas     MCnc   \n",
       "40  Indirect antiglobulin test.complement specific...  Ser/Plas     ACnc   \n",
       "..                                                ...       ...      ...   \n",
       "50                                       Levofloxacin   Isolate     Susc   \n",
       "38                                         Gentamicin   Isolate     Susc   \n",
       "19                                         Vancomycin   Isolate     Susc   \n",
       "4                                       Ciprofloxacin   Isolate     Susc   \n",
       "27                                     Antibiotic XXX   Isolate     Susc   \n",
       "\n",
       "    query  document  label  \n",
       "29      0        29     28  \n",
       "6       0         6     59  \n",
       "46      0        46     47  \n",
       "11      0        11     58  \n",
       "40      0        40     13  \n",
       "..    ...       ...    ...  \n",
       "50      0        50     29  \n",
       "38      0        38     61  \n",
       "19      0        19     56  \n",
       "4       0         4     24  \n",
       "27      0        27     43  \n",
       "\n",
       "[67 rows x 8 columns]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_query = pairs[pairs['query'] == 0]\n",
    "first_query_documents = pd.concat((documents.iloc[first_query.index, :], first_query), axis = 1)\n",
    "first_query_ranking = ranking[ranking['query'] == 0]\n",
    "ranked = first_query_documents.iloc[first_query_ranking['document'], :]\n",
    "# show results of first query, namely 'birulin in plasma'\n",
    "ranked[ranked['query'] == 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
